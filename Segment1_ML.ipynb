{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKRxKGfzl1XW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imblearn.metrics import classification_report_imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "np.ones((10, 10), dtype=bool)"
      ],
      "metadata": {
        "id": "vBFqaCPClmHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our features\n",
        "\n",
        "X = df.drop(columns='MENTAL_HEALTH_COVERAGE?')\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Create our target\n",
        "y = df.loc[:, target]"
      ],
      "metadata": {
        "id": "Wb1YnDKrlmLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "id": "SvLwZSd-lmN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of our target values\n",
        "y['MENTAL_HEALTH_COVERAGE?'].value_counts()"
      ],
      "metadata": {
        "id": "cmD0CD3XlmQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, stratify=y)\n",
        "\n",
        "Counter(y_train)"
      ],
      "metadata": {
        "id": "HU0_cM2slmSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creating a StandardScaler instance.\n",
        "scaler = StandardScaler()\n",
        "# Fitting the Standard Scaler with the training data.\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scaling the data.\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "F2KGrXQUlmVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model"
      ],
      "metadata": {
        "id": "iJRE1KyendKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions using the testing data."
      ],
      "metadata": {
        "id": "5XFxs0XnngXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculated the balanced accuracy score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculating the accuracy score.\n",
        "acc_score = accuracy_score(y_test, predictions)\n",
        "acc_score"
      ],
      "metadata": {
        "id": "dHjAvR_SnlK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the confusion matrix\n",
        "# Calculating the confusion matrix\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Create a DataFrame from the confusion matrix.\n",
        "cm_df = pd.DataFrame(\n",
        "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
        "cm_df"
      ],
      "metadata": {
        "id": "nrg3qimVnpCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the imbalanced classification report\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "2D7cZ2YlnsZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}